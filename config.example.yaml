ai:
  # For Ollama (local models) - DEFAULT:
  provider: ollama
  model: deepseek-r1:8b  # or llama3, mistral, codellama, etc.
  base_url: "http://localhost:11434"  # Default Ollama endpoint
  # Note: api_key is not required for Ollama
  
  # For OpenAI:
  # provider: openai
  # api_key: your-api-key-here
  # model: gpt-4
  # base_url: ""  # Optional: for OpenAI-compatible APIs
  
  agent:
    max_iterations: 10
    temperature: 0.7
    system_prompt: "You are WorkWise, an intelligent desktop assistant. Help users with their tasks efficiently and professionally."
    history_enabled: true
    max_history: 50

cli:
  interactive: true
  prompt: "WorkWise> "
  history_file: ~/.workwise_history

extensions:
  # Model Context Protocol (MCP) - Future support for Anthropic
  mcp_enabled: false
  mcp_servers: []
  # Example:
  # - name: "filesystem"
  #   url: "http://localhost:3000"
  
  # Skills Framework - Extensible capabilities
  skills_enabled: false
  skills_paths: []
  # Example:
  # - "./skills"
  # - "~/.workwise/skills"
  
  # Desktop Integration - Future Windows/Mac support
  desktop_enabled: false
  desktop_hotkey: ""  # e.g., "Ctrl+Alt+W"
  desktop_position: ""  # e.g., "top-right", "center"
